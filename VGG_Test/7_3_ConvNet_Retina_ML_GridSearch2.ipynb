{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 학습 세팅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 메모리 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 수정된 코드 자동 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import foolbox as fb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "import json\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from torchmetrics.aggregation import MeanMetric\n",
    "\"\"\"\n",
    "import argparse\n",
    "import easydict\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\"\"\"\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as Datasets\n",
    "\"\"\"\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\"\"\"\n",
    "import torch.utils.data as data\n",
    "\"\"\"\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchmetrics.functional.classification import accuracy\n",
    "\n",
    "from src.models import vgg11_config, vgg13_config, vgg16_config, ConvNet\n",
    "from src.models import VGG, get_vgg_layers\n",
    "from src.engines import train, evaluate, get_predictions\n",
    "from src.engines import plot_most_correct_wrong, epoch_time, normalize_image\n",
    "from src.utils import load_checkpoint, save_checkpoint, save_transform, save_best_param\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearch\n",
    "#ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import optuna\n",
    "from optuna import Trial\n",
    "from optuna.samplers import TPESampler\n",
    "#ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_valid_loss = float('inf')\n",
    "#ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
    "grid_count = 0\n",
    "#ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
    "\n",
    "def GridSearch_loop(trial: Trial) -> float:\n",
    "    #ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
    "    global grid_count\n",
    "    grid_count += 1\n",
    "    print(f\"================== {grid_count}번째 Grid ==================\")\n",
    "    #ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
    "    \n",
    "    #==================================================================================================\n",
    "    # 2. Variable Declaration\n",
    "    #==================================================================================================\n",
    "    # Jupyter 환경\n",
    "    args = easydict.EasyDict({\n",
    "            \"title\" : \"ConvNet_Retina_ML_Grid2\",\n",
    "            \"device\" : \"cuda\",\n",
    "            \"root\" : \"data\",\n",
    "            \"use_data\" : \"Retina_Some_binary\", # Retina_Some_binary # Retina_Some_binary_GAN284 # Retina_Some_binary_GAN852 # Retina_student\n",
    "            \"batch_size\" : 32, # !!!\n",
    "            \"num_workers\" : 2,\n",
    "            \"epochs\" : 200, # !!!\n",
    "            #ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
    "            # \"lr\" : 7.5e-5, # !!!\n",
    "            \"lr\" : trial.suggest_loguniform(\"lr\", 1e-6, 5e-3), # 1e-6, 5e-3 # 1e-6, 5e-5 !!!\n",
    "            #ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
    "            \"logs\" : \"logs\",\n",
    "            \"checkpoints\" : \"checkpoints\",\n",
    "            \"transform_dir\" : \"transform_infor\",\n",
    "            \"resume\" : False,\n",
    "            \"train_ratio\" : 0.8,\n",
    "            \"val_ratio\" : 0.2,\n",
    "            \"test_ratio\" : 1.0,\n",
    "            \"output_dim\" : 2,\n",
    "            \"drop_rate\": 0.5\n",
    "        })\n",
    "    \n",
    "    #ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
    "    print(\"lr : \", args.lr)\n",
    "    #ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
    "\n",
    "    #==================================================================================================\n",
    "    # 3. Image Data Preprocessing\n",
    "    # 1) 이미지 변환\n",
    "    #==================================================================================================\n",
    "    # Build Dataset\n",
    "    #ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
    "    # transform 임의 선택(1 ~ 최대 개수) + 이미지 변환\n",
    "    list_transforms = [T.RandomRotation(30), T.RandomHorizontalFlip(), T.RandomVerticalFlip(),\n",
    "                        T.RandomAutocontrast(), T.RandomPerspective(fill=[255,255,255]), T.RandomInvert(), \n",
    "                        T.RandomGrayscale(p=0.5), T.RandomEqualize(), T.AutoAugment(T.AutoAugmentPolicy.IMAGENET)]\n",
    "    \"\"\"\n",
    "    list_transforms = [T.RandomRotation(180), T.RandomHorizontalFlip(), T.RandomVerticalFlip(),\n",
    "                    T.RandomAutocontrast(), T.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 5)),\n",
    "                    T.RandomAffine(180, shear=20), T.RandomPerspective(fill=[255,255,255]),\n",
    "                    T.RandomGrayscale(p=0.5), T.RandomResizedCrop((256, 256))]\n",
    "    \"\"\"\n",
    "    \n",
    "    # rand_number_transform = random.randint(1, len(list_transforms)-1)\n",
    "    rand_number_transform = random.randint(1, 3)\n",
    "    rand_list_transforms = random.sample(list_transforms, rand_number_transform)\n",
    "\n",
    "    train_transforms = T.Compose([\n",
    "        T.Resize((256, 256)), # 이미지 크기 재조절\n",
    "        *rand_list_transforms,\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    print(\"train_transforms : \", train_transforms)\n",
    "    #ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
    "    \"\"\"\n",
    "    #ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
    "    train_transforms = T.Compose([\n",
    "        T.Resize((256, 256)), # 이미지 크기 재조절\n",
    "        T.RandomOrder([\n",
    "            # T.RandomRotation(5), # 이미지 회전(5도 이하)\n",
    "            # T.RandomHorizontalFlip(0.5), # 이미지 좌우 대칭(50% 확률)\n",
    "    #         T.RandomRotation(180),\n",
    "            T.RandomHorizontalFlip(),\n",
    "            T.RandomVerticalFlip(),\n",
    "            T.RandomAutocontrast(),\n",
    "    #         T.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 5)),\n",
    "    #         T.RandomAffine(180, shear=20),\n",
    "    #         T.RandomPerspective(fill=[255,255,255]),\n",
    "    #         T.RandomGrayscale(p=0.5),\n",
    "    #         T.RandomResizedCrop((256, 256)),\n",
    "        ]),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    #ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
    "    \"\"\"\n",
    "\n",
    "    test_transforms = T.Compose([\n",
    "        T.Resize((256, 256)), \n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # transform 정보 저장\n",
    "    save_transform(args.transform_dir, train_transforms, test_transforms, args.title)\n",
    "\n",
    "    #==================================================================================================\n",
    "    # 2) 이미지 데이터셋 불러오기 + 이미지 변환\n",
    "    #==================================================================================================\n",
    "    train_path = f'C:\\\\Users\\\\Bang\\\\JupyterProjects\\\\RetinaProject\\\\DeepLearningPytorchExample\\\\data\\\\{args.use_data}\\\\train' \n",
    "    test_path = f'C:\\\\Users\\\\Bang\\\\JupyterProjects\\\\RetinaProject\\\\DeepLearningPytorchExample\\\\data\\\\{args.use_data}\\\\test'\n",
    "\n",
    "    train_dataset = torchvision.datasets.ImageFolder(\n",
    "        train_path, \n",
    "        transform = train_transforms\n",
    "    )\n",
    "    test_dataset = torchvision.datasets.ImageFolder(\n",
    "        test_path, \n",
    "        transform = test_transforms\n",
    "    )\n",
    "\n",
    "    train_dataset_classes = train_dataset.classes\n",
    "    test_dataset_classes = test_dataset.classes\n",
    "\n",
    "    print(\"len(train_dataset) : \", len(train_dataset))\n",
    "    print(\"train_dataset_classes : \", train_dataset_classes)\n",
    "    print(\"train_dataset.__getitem__(18) : \", train_dataset.__getitem__(18))\n",
    "\n",
    "    print(\"len(test_dataset) : \", len(test_dataset))\n",
    "    print(\"test_dataset_classes : \", test_dataset_classes)\n",
    "    print(\"test_dataset.__getitem__(18) : \", test_dataset.__getitem__(18))\n",
    "    \n",
    "    #==================================================================================================\n",
    "    # 3) 훈련, 검증 데이터 분할 + 검증 이미지 재변환\n",
    "    #==================================================================================================\n",
    "    all_train_dataset_size = len(train_dataset)\n",
    "    train_dataset_size = int(all_train_dataset_size * args.train_ratio)\n",
    "    valid_dataset_size = all_train_dataset_size - train_dataset_size\n",
    "\n",
    "    splited_train_dataset, splited_valid_dataset = random_split(train_dataset, [train_dataset_size, valid_dataset_size]) # 훈련 데이터셋, 검증 데이터셋 크기 결정\n",
    "\n",
    "    splited_valid_dataset = copy.deepcopy(splited_valid_dataset)\n",
    "    splited_valid_dataset.dataset.transform = test_transforms\n",
    "\n",
    "    #==================================================================================================\n",
    "    # 4) 데이터 로드 to 메모리\n",
    "    #==================================================================================================\n",
    "    train_loader = DataLoader(splited_train_dataset,\n",
    "                                shuffle = True,\n",
    "                                batch_size = args.batch_size, \n",
    "                                num_workers=args.num_workers\n",
    "                            )\n",
    "    val_loader = DataLoader(splited_valid_dataset,\n",
    "                                batch_size = args.batch_size,\n",
    "                                num_workers=args.num_workers\n",
    "                            )\n",
    "    test_loader = DataLoader(test_dataset,\n",
    "                                batch_size = args.batch_size,\n",
    "                                num_workers=args.num_workers\n",
    "                            )\n",
    "\n",
    "    print(f\"train_dataset 개수 : {len(splited_train_dataset)}, \" + f\"train_loader 개수 : {len(train_loader)}\") # train_data 개수, train_loader batch set 개수\n",
    "    print(f\"val_dataset 개수 : {len(splited_valid_dataset)}, \" + f\"val_loader 개수 : {len(val_loader)}\") # val_data 개수, val_loader batch set 개수\n",
    "    print(f\"test_dataset 개수 : {len(test_dataset)}, \" + f\"test_loader 개수 : {len(test_loader)}\") # test_data 개수, test_loader batch set 개수\n",
    "\n",
    "    #==================================================================================================\n",
    "    # 5) 시각화\n",
    "    #==================================================================================================\n",
    "    train_loader_iter = iter(train_loader)\n",
    "    train_loader_images, train_loader_labels = train_loader_iter.next()\n",
    "\n",
    "    test_loader_iter = iter(test_loader)\n",
    "    test_loader_images, test_loader_labels = test_loader_iter.next()\n",
    "\n",
    "    def imshow(img):\n",
    "        np_img = img.numpy()\n",
    "        plt.imshow(np.transpose(np_img, (1, 2, 0)))\n",
    "\n",
    "        \"\"\"\n",
    "        print(\"np_img.shape : \", np_img.shape)\n",
    "        print(\"(np.transpose(np_img, (1, 2, 0))).shape : \", (np.transpose(np_img, (1, 2, 0))).shape)\n",
    "        \"\"\"\n",
    "\n",
    "    print(\"train_loader_labels : \", train_loader_labels)\n",
    "    print(\"\".join(\"%5s \"%train_dataset_classes[train_loader_labels[j]] for j in range(32)))\n",
    "    print(\"train_loader_images.shape : \", train_loader_images.shape)\n",
    "    imshow(torchvision.utils.make_grid(train_loader_images, nrow=6))\n",
    "    print(\"torchvision.utils.make_grid(train_loader_images).shape : \", torchvision.utils.make_grid(train_loader_images).shape)\n",
    "\n",
    "    print(\"test_loader_labels : \", test_loader_labels)\n",
    "    print(\"\".join(\"%5s \"%test_dataset_classes[test_loader_labels[j]] for j in range(32)))\n",
    "    print(\"test_loader_images.shape : \", test_loader_images.shape)\n",
    "    imshow(torchvision.utils.make_grid(test_loader_images, nrow=6))\n",
    "    print(\"torchvision.utils.make_grid(test_loader_images).shape : \", torchvision.utils.make_grid(test_loader_images).shape)\n",
    "    \n",
    "    #==================================================================================================\n",
    "    # 4. Model Define\n",
    "    # 1) 모델 정의\n",
    "    #==================================================================================================\n",
    "    #ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
    "    \"\"\"\n",
    "    # Build model\n",
    "    vgg11_layers = get_vgg_layers(vgg11_config, batch_norm = True)\n",
    "    model = VGG(vgg11_layers, args.output_dim)\n",
    "    \"\"\"\n",
    "    model = ConvNet(drop_rate=args.drop_rate)\n",
    "    #ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
    "    model = model.to(args.device)\n",
    "\n",
    "    #==================================================================================================\n",
    "    # 2) 옵티마이저 + 손실함수 + 스케쥴러 + 메트릭 함수 정의\n",
    "    #==================================================================================================\n",
    "    # Build optimizer \n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "    # Build scheduler\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, args.epochs * len(train_loader))\n",
    "\n",
    "    # Build loss function\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Build metric function\n",
    "    \"\"\"\n",
    "    # 정확도 측정 함수\n",
    "    def calculate_accuracy(y_pred, y): # ???\n",
    "        top_pred = y_pred.argmax(1, keepdim = True)\n",
    "        # print(\"top_pred : \", top_pred)\n",
    "        correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "        # print(\"correct : \", correct)\n",
    "        acc = correct.float() / y.shape[0]\n",
    "        # print(\"acc : \", acc)\n",
    "        return acc\n",
    "    \"\"\"\n",
    "    metric_fn = accuracy\n",
    "\n",
    "    #==================================================================================================\n",
    "    # 3) logger 정의\n",
    "    #==================================================================================================\n",
    "    #ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
    "    # Build logger\n",
    "    train_logger = SummaryWriter(f'{args.logs}/train/{args.title}_{grid_count}')\n",
    "    val_logger = SummaryWriter(f'{args.logs}/val/{args.title}_{grid_count}')\n",
    "    test_logger = SummaryWriter(f'{args.logs}/test/{args.title}_{grid_count}')\n",
    "    #ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
    "\n",
    "    #==================================================================================================\n",
    "    # 5. Model Train\n",
    "    # 1) Load model epoch\n",
    "    #==================================================================================================\n",
    "    # Load model\n",
    "    start_epoch = 0\n",
    "    if args.resume:\n",
    "        start_epoch = load_checkpoint(args.checkpoints, args.title, model, optimizer)\n",
    "\n",
    "    #==================================================================================================\n",
    "    # 2) Train model\n",
    "    #==================================================================================================\n",
    "    for epoch in range(start_epoch, args.epochs):\n",
    "        \"\"\"\n",
    "        # start timer\n",
    "        start_time = time.time() # 확인용 코드\n",
    "        \"\"\"\n",
    "        # 모델 학습 소요시간\n",
    "        start_time = time.monotonic()\n",
    "\n",
    "        # train one epoch + evaluate one epoch\n",
    "        train_summary = train(train_loader, model, optimizer, scheduler, loss_fn, metric_fn, args.device)\n",
    "        val_summary = evaluate(val_loader, model, loss_fn, metric_fn, args.device)\n",
    "\n",
    "        # write log\n",
    "        #ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
    "        train_logger.add_scalar(f'Loss_{args.lr}', train_summary['loss'], epoch + 1)\n",
    "        train_logger.add_scalar(f'Accuracy_{args.lr}', train_summary['metric'], epoch + 1)\n",
    "        val_logger.add_scalar(f'Loss_{args.lr}', val_summary['loss'], epoch + 1)\n",
    "        val_logger.add_scalar(f'Accuracy_{args.lr}', val_summary['metric'], epoch + 1)\n",
    "        #ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
    "        \"\"\"\n",
    "        #ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
    "        train_logger.add_scalar('Loss', train_summary['loss'], epoch + 1)\n",
    "        train_logger.add_scalar('Accuracy', train_summary['metric'], epoch + 1)\n",
    "        val_logger.add_scalar('Loss', val_summary['loss'], epoch + 1)\n",
    "        val_logger.add_scalar('Accuracy', val_summary['metric'], epoch + 1)\n",
    "        #ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
    "        \"\"\"\n",
    "\n",
    "        # 최적 loss인 model 저장\n",
    "        global best_valid_loss\n",
    "        if val_summary['loss'] < best_valid_loss:\n",
    "            best_valid_loss = val_summary['loss']\n",
    "            #ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
    "            torch.save(model.state_dict(), f'C:\\\\Users\\\\Bang\\\\JupyterProjects\\\\RetinaProject\\\\DeepLearningPytorchExample\\\\best_valid_model\\\\{args.title}_{grid_count}.pt')\n",
    "            save_best_param(args.transform_dir, train_transforms, test_transforms, args.lr, args.title)\n",
    "        torch.save(model.state_dict(), f'C:\\\\Users\\\\Bang\\\\JupyterProjects\\\\RetinaProject\\\\DeepLearningPytorchExample\\\\best_valid_model\\\\{args.title}.pt')\n",
    "            #ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
    "\n",
    "        \"\"\"\n",
    "        #ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
    "        # save model\n",
    "        save_checkpoint(args.checkpoints, args.title, model, optimizer, epoch + 1)\n",
    "        #ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
    "        \"\"\"\n",
    "\n",
    "        # 모델 학습 소요시간\n",
    "        end_time = time.monotonic()\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        # Print log\n",
    "        \"\"\"\n",
    "        print((\n",
    "            f'[Epoch {epoch+1}] '\n",
    "            + f'{epoch + 1}epoch time {end_time - start_time:.02f}, '\n",
    "            + f'Train Loss {train_summary[\"loss\"]:.04f}, '\n",
    "            + f'Train Accuracy {train_summary[\"metric\"]:.04f}, '\n",
    "            + f'Test Loss {val_summary[\"loss\"]:.04f}, '\n",
    "            + f'Test Accuracy {val_summary[\"metric\"]:.04f}'\n",
    "        ))\n",
    "        \"\"\"\n",
    "        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "        print(f'\\t Train Loss: {train_summary[\"loss\"]:.3f} | Train Acc: {train_summary[\"metric\"]:.2f}%')\n",
    "        print(f'\\t Valid Loss: {val_summary[\"loss\"]:.3f} | Valid Acc: {val_summary[\"metric\"]:.2f}%')\n",
    "        print(f'\\t scheduled_lr : {scheduler.get_last_lr()[0]}')\n",
    "\n",
    "    #==================================================================================================\n",
    "    # 6. Model Test\n",
    "    #==================================================================================================\n",
    "    # 학습된 모델 불러오기\n",
    "    model.load_state_dict(torch.load(f'C:\\\\Users\\\\Bang\\\\JupyterProjects\\\\RetinaProject\\\\DeepLearningPytorchExample\\\\best_valid_model\\\\{args.title}.pt'))\n",
    "\n",
    "    # 모델 성능 측정\n",
    "    test_summary = evaluate(test_loader, model, loss_fn, metric_fn, args.device)\n",
    "\n",
    "    # write log\n",
    "    test_logger.add_scalar('Loss', test_summary['loss'], epoch + 1)\n",
    "    test_logger.add_scalar('Accuracy', test_summary['metric'], epoch + 1)\n",
    "\n",
    "    print(f'Test Loss: {test_summary[\"loss\"]:.3f} | Test Acc: {test_summary[\"metric\"]:.2f}%')\n",
    "\n",
    "    #==================================================================================================\n",
    "    # 7. Model Prediction Print\n",
    "    # 1) 예측한 값 추출 + 맞춘 이미지 정보 추출 + 틀린 이미지 정보 추출\n",
    "    #==================================================================================================\n",
    "    correct_examples, wrong_examples = get_predictions(test_loader, model, args.device)\n",
    "\n",
    "#     for correct_example in correct_examples: # 확인용 코드\n",
    "#         print(\"correct_example : \", correct_example[2])\n",
    "#     for wrong_example in wrong_examples: # 확인용 코드\n",
    "#         print(\"wrong_example : \", wrong_example[2])\n",
    "\n",
    "    classes = test_dataset.classes\n",
    "    n_images = 5\n",
    "    plot_most_correct_wrong(correct_examples, wrong_examples, classes, n_images)\n",
    "\n",
    "    #==================================================================================================\n",
    "    # 3) return loss\n",
    "    #==================================================================================================\n",
    "    return val_summary[\"loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-02 00:09:20,923]\u001b[0m A new study created in memory with name: Retina_opt\u001b[0m\n",
      "C:\\Users\\Bang\\AppData\\Local\\Temp\\ipykernel_7768\\1859775794.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  \"lr\" : trial.suggest_loguniform(\"lr\", 1e-6, 5e-3), # 1e-6, 5e-3 # 1e-6, 5e-5 !!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== 1번째 Grid ==================\n",
      "lr :  2.428916946974887e-05\n",
      "train_transforms :  Compose(\n",
      "    Resize(size=(256, 256), interpolation=bilinear)\n",
      "    RandomEqualize(p=0.5)\n",
      "    RandomPerspective(p=0.5)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n",
      "len(train_dataset) :  4532\n",
      "train_dataset_classes :  ['DR', 'No_DR']\n",
      "train_dataset.__getitem__(18) :  (tensor([[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         ...,\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "        [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         ...,\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "        [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         ...,\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]]), 0)\n",
      "len(test_dataset) :  1132\n",
      "test_dataset_classes :  ['DR', 'No_DR']\n",
      "test_dataset.__getitem__(18) :  (tensor([[[-2.1179, -2.1008, -2.1008,  ..., -2.1179, -2.1008, -2.0837],\n",
      "         [-2.1008, -2.1008, -2.1008,  ..., -2.1179, -2.1008, -2.0665],\n",
      "         [-2.1179, -2.1008, -2.1008,  ..., -2.1179, -2.1008, -2.0837],\n",
      "         ...,\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1008, -2.0837, -2.0494],\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1008, -2.0665],\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1008, -2.0665, -2.1008]],\n",
      "\n",
      "        [[-2.0007, -2.0182, -2.0182,  ..., -1.9832, -1.9832, -2.0007],\n",
      "         [-2.0182, -1.9832, -2.0007,  ..., -2.0182, -2.0007, -1.9832],\n",
      "         [-2.0007, -2.0007, -2.0182,  ..., -1.9832, -1.9832, -1.9657],\n",
      "         ...,\n",
      "         [-2.0357, -2.0357, -2.0182,  ..., -1.9482, -1.9482, -1.9307],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -1.9657, -1.9657, -1.9482],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -1.9657, -1.9657, -1.9482]],\n",
      "\n",
      "        [[-1.7870, -1.7870, -1.7870,  ..., -1.8044, -1.7870, -1.7696],\n",
      "         [-1.7870, -1.8044, -1.7870,  ..., -1.7696, -1.7696, -1.7522],\n",
      "         [-1.8044, -1.7870, -1.7870,  ..., -1.7870, -1.7870, -1.7696],\n",
      "         ...,\n",
      "         [-1.8044, -1.8044, -1.7870,  ..., -1.7696, -1.7347, -1.7522],\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.7522, -1.7347, -1.7696],\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.7522, -1.7522, -1.7696]]]), 0)\n",
      "train_dataset 개수 : 3625, train_loader 개수 : 114\n",
      "val_dataset 개수 : 907, val_loader 개수 : 29\n",
      "test_dataset 개수 : 1132, test_loader 개수 : 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loader_labels :  tensor([1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "        1, 1, 0, 1, 1, 1, 1, 1])\n",
      "No_DR No_DR    DR    DR No_DR No_DR No_DR    DR No_DR No_DR    DR    DR No_DR No_DR    DR No_DR No_DR No_DR No_DR No_DR No_DR    DR    DR No_DR No_DR No_DR    DR No_DR No_DR No_DR No_DR No_DR \n",
      "train_loader_images.shape :  torch.Size([32, 3, 256, 256])\n",
      "torchvision.utils.make_grid(train_loader_images).shape :  torch.Size([3, 1034, 2066])\n",
      "test_loader_labels :  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "   DR    DR    DR    DR    DR    DR    DR    DR    DR    DR    DR    DR    DR    DR    DR    DR    DR    DR    DR    DR    DR    DR    DR    DR    DR    DR    DR    DR    DR    DR    DR    DR \n",
      "test_loader_images.shape :  torch.Size([32, 3, 256, 256])\n",
      "torchvision.utils.make_grid(test_loader_images).shape :  torch.Size([3, 1034, 2066])\n",
      "Epoch: 01 | Epoch Time: 0m 18s\n",
      "\t Train Loss: 0.693 | Train Acc: 0.50%\n",
      "\t Valid Loss: 0.693 | Valid Acc: 0.50%\n",
      "\t scheduled_lr : 2.4287671222468855e-05\n",
      "Epoch: 02 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.694 | Train Acc: 0.49%\n",
      "\t Valid Loss: 0.693 | Valid Acc: 0.52%\n",
      "\t scheduled_lr : 2.4283176850298953e-05\n",
      "Epoch: 03 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.693 | Train Acc: 0.51%\n",
      "\t Valid Loss: 0.693 | Valid Acc: 0.52%\n",
      "\t scheduled_lr : 2.4275687462158208e-05\n",
      "Epoch: 04 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.693 | Train Acc: 0.52%\n",
      "\t Valid Loss: 0.692 | Valid Acc: 0.52%\n",
      "\t scheduled_lr : 2.4265204905941128e-05\n",
      "Epoch: 05 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.693 | Train Acc: 0.50%\n",
      "\t Valid Loss: 0.692 | Valid Acc: 0.52%\n",
      "\t scheduled_lr : 2.425173176806153e-05\n",
      "Epoch: 06 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.693 | Train Acc: 0.51%\n",
      "\t Valid Loss: 0.693 | Valid Acc: 0.53%\n",
      "\t scheduled_lr : 2.423527137281463e-05\n",
      "Epoch: 07 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.693 | Train Acc: 0.51%\n",
      "\t Valid Loss: 0.692 | Valid Acc: 0.51%\n",
      "\t scheduled_lr : 2.421582778155665e-05\n",
      "Epoch: 08 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.693 | Train Acc: 0.51%\n",
      "\t Valid Loss: 0.693 | Valid Acc: 0.49%\n",
      "\t scheduled_lr : 2.419340579170279e-05\n",
      "Epoch: 09 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.693 | Train Acc: 0.51%\n",
      "\t Valid Loss: 0.693 | Valid Acc: 0.49%\n",
      "\t scheduled_lr : 2.4168010935543493e-05\n",
      "Epoch: 10 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.692 | Train Acc: 0.52%\n",
      "\t Valid Loss: 0.692 | Valid Acc: 0.53%\n",
      "\t scheduled_lr : 2.4139649478879613e-05\n",
      "Epoch: 11 | Epoch Time: 0m 18s\n",
      "\t Train Loss: 0.693 | Train Acc: 0.51%\n",
      "\t Valid Loss: 0.691 | Valid Acc: 0.53%\n",
      "\t scheduled_lr : 2.410832841947615e-05\n",
      "Epoch: 12 | Epoch Time: 0m 18s\n",
      "\t Train Loss: 0.693 | Train Acc: 0.52%\n",
      "\t Valid Loss: 0.691 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 2.4074055485335853e-05\n",
      "Epoch: 13 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.693 | Train Acc: 0.51%\n",
      "\t Valid Loss: 0.690 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 2.4036839132792364e-05\n",
      "Epoch: 14 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.692 | Train Acc: 0.52%\n",
      "\t Valid Loss: 0.690 | Valid Acc: 0.51%\n",
      "\t scheduled_lr : 2.3996688544423817e-05\n",
      "Epoch: 15 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.693 | Train Acc: 0.50%\n",
      "\t Valid Loss: 0.689 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 2.3953613626787118e-05\n",
      "Epoch: 16 | Epoch Time: 0m 18s\n",
      "\t Train Loss: 0.691 | Train Acc: 0.52%\n",
      "\t Valid Loss: 0.689 | Valid Acc: 0.54%\n",
      "\t scheduled_lr : 2.390762500797361e-05\n",
      "Epoch: 17 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.691 | Train Acc: 0.53%\n",
      "\t Valid Loss: 0.692 | Valid Acc: 0.52%\n",
      "\t scheduled_lr : 2.3858734034986878e-05\n",
      "Epoch: 18 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.690 | Train Acc: 0.54%\n",
      "\t Valid Loss: 0.687 | Valid Acc: 0.54%\n",
      "\t scheduled_lr : 2.380695277094292e-05\n",
      "Epoch: 19 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.691 | Train Acc: 0.52%\n",
      "\t Valid Loss: 0.685 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 2.3752293992093835e-05\n",
      "Epoch: 20 | Epoch Time: 0m 18s\n",
      "\t Train Loss: 0.691 | Train Acc: 0.53%\n",
      "\t Valid Loss: 0.685 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 2.369477118467539e-05\n",
      "Epoch: 21 | Epoch Time: 0m 18s\n",
      "\t Train Loss: 0.690 | Train Acc: 0.54%\n",
      "\t Valid Loss: 0.689 | Valid Acc: 0.52%\n",
      "\t scheduled_lr : 2.363439854157962e-05\n",
      "Epoch: 22 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.688 | Train Acc: 0.54%\n",
      "\t Valid Loss: 0.692 | Valid Acc: 0.52%\n",
      "\t scheduled_lr : 2.3571190958852787e-05\n",
      "Epoch: 23 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.688 | Train Acc: 0.54%\n",
      "\t Valid Loss: 0.683 | Valid Acc: 0.57%\n",
      "\t scheduled_lr : 2.350516403202019e-05\n",
      "Epoch: 24 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.689 | Train Acc: 0.53%\n",
      "\t Valid Loss: 0.688 | Valid Acc: 0.54%\n",
      "\t scheduled_lr : 2.343633405223802e-05\n",
      "Epoch: 25 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.688 | Train Acc: 0.53%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 2.3364718002273876e-05\n",
      "Epoch: 26 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.688 | Train Acc: 0.54%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 2.3290333552316453e-05\n",
      "Epoch: 27 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.689 | Train Acc: 0.55%\n",
      "\t Valid Loss: 0.683 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 2.3213199055615747e-05\n",
      "Epoch: 28 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.689 | Train Acc: 0.54%\n",
      "\t Valid Loss: 0.690 | Valid Acc: 0.53%\n",
      "\t scheduled_lr : 2.3133333543954643e-05\n",
      "Epoch: 29 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.688 | Train Acc: 0.54%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 2.305075672295304e-05\n",
      "Epoch: 30 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.687 | Train Acc: 0.54%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 2.2965488967205966e-05\n",
      "Epoch: 31 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.687 | Train Acc: 0.54%\n",
      "\t Valid Loss: 0.683 | Valid Acc: 0.57%\n",
      "\t scheduled_lr : 2.2877551315256226e-05\n",
      "Epoch: 32 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.687 | Train Acc: 0.55%\n",
      "\t Valid Loss: 0.685 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 2.2786965464403596e-05\n",
      "Epoch: 33 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.689 | Train Acc: 0.54%\n",
      "\t Valid Loss: 0.683 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 2.269375376535129e-05\n",
      "Epoch: 34 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.687 | Train Acc: 0.54%\n",
      "\t Valid Loss: 0.686 | Valid Acc: 0.54%\n",
      "\t scheduled_lr : 2.2597939216691342e-05\n",
      "Epoch: 35 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.689 | Train Acc: 0.53%\n",
      "\t Valid Loss: 0.687 | Valid Acc: 0.54%\n",
      "\t scheduled_lr : 2.2499545459229914e-05\n",
      "Epoch: 36 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.687 | Train Acc: 0.54%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 2.2398596770154345e-05\n",
      "Epoch: 37 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.685 | Train Acc: 0.55%\n",
      "\t Valid Loss: 0.685 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 2.229511805704314e-05\n",
      "Epoch: 38 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.688 | Train Acc: 0.54%\n",
      "\t Valid Loss: 0.683 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 2.2189134851720397e-05\n",
      "Epoch: 39 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.685 | Train Acc: 0.55%\n",
      "\t Valid Loss: 0.685 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 2.208067330395613e-05\n",
      "Epoch: 40 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.687 | Train Acc: 0.54%\n",
      "\t Valid Loss: 0.685 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 2.1969760175014366e-05\n",
      "Epoch: 41 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.683 | Train Acc: 0.55%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 2.1856422831049984e-05\n",
      "Epoch: 42 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.686 | Train Acc: 0.55%\n",
      "\t Valid Loss: 0.688 | Valid Acc: 0.54%\n",
      "\t scheduled_lr : 2.1740689236356738e-05\n",
      "Epoch: 43 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.686 | Train Acc: 0.55%\n",
      "\t Valid Loss: 0.683 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 2.1622587946467327e-05\n",
      "Epoch: 44 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.685 | Train Acc: 0.55%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 2.1502148101107853e-05\n",
      "Epoch: 45 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.688 | Train Acc: 0.53%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 2.1379399417007996e-05\n",
      "Epoch: 46 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.686 | Train Acc: 0.54%\n",
      "\t Valid Loss: 0.682 | Valid Acc: 0.57%\n",
      "\t scheduled_lr : 2.1254372180568838e-05\n",
      "Epoch: 47 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.686 | Train Acc: 0.55%\n",
      "\t Valid Loss: 0.683 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 2.1127097240390097e-05\n",
      "Epoch: 48 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.686 | Train Acc: 0.55%\n",
      "\t Valid Loss: 0.683 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 2.099760599965884e-05\n",
      "Epoch: 49 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.684 | Train Acc: 0.55%\n",
      "\t Valid Loss: 0.686 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 2.086593040840111e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.687 | Train Acc: 0.54%\n",
      "\t Valid Loss: 0.683 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 2.0732102955598735e-05\n",
      "Epoch: 51 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.683 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.688 | Valid Acc: 0.54%\n",
      "\t scheduled_lr : 2.059615666117319e-05\n",
      "Epoch: 52 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.683 | Train Acc: 0.57%\n",
      "\t Valid Loss: 0.683 | Valid Acc: 0.54%\n",
      "\t scheduled_lr : 2.0458125067838433e-05\n",
      "Epoch: 53 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.685 | Train Acc: 0.55%\n",
      "\t Valid Loss: 0.683 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 2.0318042232824677e-05\n",
      "Epoch: 54 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.683 | Train Acc: 0.55%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 2.0175942719475385e-05\n",
      "Epoch: 55 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.682 | Train Acc: 0.55%\n",
      "\t Valid Loss: 0.685 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 2.0031861588719147e-05\n",
      "Epoch: 56 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.685 | Train Acc: 0.55%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 1.9885834390419107e-05\n",
      "Epoch: 57 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.687 | Train Acc: 0.55%\n",
      "\t Valid Loss: 0.686 | Valid Acc: 0.54%\n",
      "\t scheduled_lr : 1.973789715460136e-05\n",
      "Epoch: 58 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.684 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 1.958808638256522e-05\n",
      "Epoch: 59 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.685 | Train Acc: 0.55%\n",
      "\t Valid Loss: 0.685 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 1.9436439037877002e-05\n",
      "Epoch: 60 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.683 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.683 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 1.9282992537249894e-05\n",
      "Epoch: 61 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.682 | Train Acc: 0.57%\n",
      "\t Valid Loss: 0.685 | Valid Acc: 0.57%\n",
      "\t scheduled_lr : 1.9127784741311827e-05\n",
      "Epoch: 62 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.681 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.683 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 1.8970853945264063e-05\n",
      "Epoch: 63 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.682 | Train Acc: 0.57%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 1.881223886943226e-05\n",
      "Epoch: 64 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.685 | Train Acc: 0.54%\n",
      "\t Valid Loss: 0.683 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 1.8651978649713024e-05\n",
      "Epoch: 65 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.683 | Train Acc: 0.57%\n",
      "\t Valid Loss: 0.683 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 1.849011282791754e-05\n",
      "Epoch: 66 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.685 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.682 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 1.8326681342015238e-05\n",
      "Epoch: 67 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.687 | Train Acc: 0.54%\n",
      "\t Valid Loss: 0.682 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 1.8161724516279858e-05\n",
      "Epoch: 68 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.683 | Train Acc: 0.55%\n",
      "\t Valid Loss: 0.682 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 1.7995283051339796e-05\n",
      "Epoch: 69 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.683 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.683 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 1.7827398014135997e-05\n",
      "Epoch: 70 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.682 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.683 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 1.7658110827789314e-05\n",
      "Epoch: 71 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.682 | Train Acc: 0.57%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 1.748746326137988e-05\n",
      "Epoch: 72 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.681 | Train Acc: 0.57%\n",
      "\t Valid Loss: 0.687 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 1.731549741964124e-05\n",
      "Epoch: 73 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.683 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.683 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 1.714225573257168e-05\n",
      "Epoch: 74 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.685 | Train Acc: 0.55%\n",
      "\t Valid Loss: 0.683 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 1.6967780944965178e-05\n",
      "Epoch: 75 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.685 | Train Acc: 0.55%\n",
      "\t Valid Loss: 0.682 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 1.679211610586488e-05\n",
      "Epoch: 76 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.685 | Train Acc: 0.55%\n",
      "\t Valid Loss: 0.685 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 1.6615304557941294e-05\n",
      "Epoch: 77 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.683 | Train Acc: 0.55%\n",
      "\t Valid Loss: 0.682 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 1.6437389926798192e-05\n",
      "Epoch: 78 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.682 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.682 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 1.625841611020858e-05\n",
      "Epoch: 79 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.682 | Train Acc: 0.57%\n",
      "\t Valid Loss: 0.682 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 1.6078427267283688e-05\n",
      "Epoch: 80 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.680 | Train Acc: 0.57%\n",
      "\t Valid Loss: 0.685 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 1.5897467807577266e-05\n",
      "Epoch: 81 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.680 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.690 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 1.5715582380128237e-05\n",
      "Epoch: 82 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.680 | Train Acc: 0.57%\n",
      "\t Valid Loss: 0.686 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 1.553281586244424e-05\n",
      "Epoch: 83 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.682 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.688 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 1.5349213349428678e-05\n",
      "Epoch: 84 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.681 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 1.5164820142254392e-05\n",
      "Epoch: 85 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.685 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.683 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 1.4979681737186079e-05\n",
      "Epoch: 86 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.680 | Train Acc: 0.58%\n",
      "\t Valid Loss: 0.683 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 1.4793843814354931e-05\n",
      "Epoch: 87 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.682 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.686 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 1.4607352226487622e-05\n",
      "Epoch: 88 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.685 | Train Acc: 0.54%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 1.4420252987592947e-05\n",
      "Epoch: 89 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.682 | Train Acc: 0.55%\n",
      "\t Valid Loss: 0.682 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 1.423259226160847e-05\n",
      "Epoch: 90 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.683 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.683 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 1.4044416351010292e-05\n",
      "Epoch: 91 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.685 | Train Acc: 0.55%\n",
      "\t Valid Loss: 0.682 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 1.3855771685388626e-05\n",
      "Epoch: 92 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.681 | Train Acc: 0.57%\n",
      "\t Valid Loss: 0.682 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 1.3666704809991958e-05\n",
      "Epoch: 93 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.679 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.682 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 1.3477262374242724e-05\n",
      "Epoch: 94 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.684 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.682 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 1.3287491120227272e-05\n",
      "Epoch: 95 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.679 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 1.3097437871162906e-05\n",
      "Epoch: 96 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.679 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 1.2907149519844997e-05\n",
      "Epoch: 97 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.683 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.683 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 1.2716673017076897e-05\n",
      "Epoch: 98 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.679 | Train Acc: 0.57%\n",
      "\t Valid Loss: 0.687 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 1.2526055360085504e-05\n",
      "Epoch: 99 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.678 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 1.2335343580925425e-05\n",
      "Epoch: 100 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.681 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 1.2144584734874452e-05\n",
      "Epoch: 101 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.681 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 1.1953825888823475e-05\n",
      "Epoch: 102 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.679 | Train Acc: 0.57%\n",
      "\t Valid Loss: 0.686 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 1.176311410966339e-05\n",
      "Epoch: 103 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.682 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.685 | Valid Acc: 0.54%\n",
      "\t scheduled_lr : 1.1572496452672002e-05\n",
      "Epoch: 104 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.681 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.683 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 1.1382019949903907e-05\n",
      "Epoch: 105 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.681 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.686 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 1.1191731598586003e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 106 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.679 | Train Acc: 0.57%\n",
      "\t Valid Loss: 0.683 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 1.1001678349521627e-05\n",
      "Epoch: 107 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.685 | Train Acc: 0.55%\n",
      "\t Valid Loss: 0.683 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 1.0811907095506165e-05\n",
      "Epoch: 108 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.680 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 1.0622464659756948e-05\n",
      "Epoch: 109 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.677 | Train Acc: 0.57%\n",
      "\t Valid Loss: 0.685 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 1.0433397784360272e-05\n",
      "Epoch: 110 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.683 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.683 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 1.0244753118738588e-05\n",
      "Epoch: 111 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.679 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.688 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 1.0056577208140412e-05\n",
      "Epoch: 112 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.683 | Train Acc: 0.55%\n",
      "\t Valid Loss: 0.683 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 9.86891648215594e-06\n",
      "Epoch: 113 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.679 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 9.68181724326126e-06\n",
      "Epoch: 114 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.679 | Train Acc: 0.57%\n",
      "\t Valid Loss: 0.683 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 9.495325655393944e-06\n",
      "Epoch: 115 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.681 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.682 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 9.309487732562786e-06\n",
      "Epoch: 116 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.678 | Train Acc: 0.57%\n",
      "\t Valid Loss: 0.683 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 9.12434932749449e-06\n",
      "Epoch: 117 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.678 | Train Acc: 0.57%\n",
      "\t Valid Loss: 0.683 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 8.939956120320197e-06\n",
      "Epoch: 118 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.676 | Train Acc: 0.58%\n",
      "\t Valid Loss: 0.688 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 8.756353607304666e-06\n",
      "Epoch: 119 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.678 | Train Acc: 0.57%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.54%\n",
      "\t scheduled_lr : 8.573587089620663e-06\n",
      "Epoch: 120 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.681 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.54%\n",
      "\t scheduled_lr : 8.391701662171648e-06\n",
      "Epoch: 121 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.683 | Train Acc: 0.55%\n",
      "\t Valid Loss: 0.682 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 8.210742202465246e-06\n",
      "Epoch: 122 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.680 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.683 | Valid Acc: 0.54%\n",
      "\t scheduled_lr : 8.030753359540344e-06\n",
      "Epoch: 123 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.678 | Train Acc: 0.58%\n",
      "\t Valid Loss: 0.687 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 7.851779542950724e-06\n",
      "Epoch: 124 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.680 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.685 | Valid Acc: 0.54%\n",
      "\t scheduled_lr : 7.673864911807606e-06\n",
      "Epoch: 125 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.677 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.683 | Valid Acc: 0.56%\n",
      "\t scheduled_lr : 7.497053363884004e-06\n",
      "Epoch: 126 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.679 | Train Acc: 0.57%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 7.321388524783682e-06\n",
      "Epoch: 127 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.676 | Train Acc: 0.58%\n",
      "\t Valid Loss: 0.686 | Valid Acc: 0.54%\n",
      "\t scheduled_lr : 7.146913737177177e-06\n",
      "Epoch: 128 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.678 | Train Acc: 0.57%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 6.973672050107599e-06\n",
      "Epoch: 129 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.679 | Train Acc: 0.58%\n",
      "\t Valid Loss: 0.688 | Valid Acc: 0.54%\n",
      "\t scheduled_lr : 6.801706208368952e-06\n",
      "Epoch: 130 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.677 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.686 | Valid Acc: 0.54%\n",
      "\t scheduled_lr : 6.631058641959514e-06\n",
      "Epoch: 131 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.679 | Train Acc: 0.57%\n",
      "\t Valid Loss: 0.685 | Valid Acc: 0.54%\n",
      "\t scheduled_lr : 6.461771455612838e-06\n",
      "Epoch: 132 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.680 | Train Acc: 0.57%\n",
      "\t Valid Loss: 0.685 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 6.2938864184090615e-06\n",
      "Epoch: 133 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.680 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.685 | Valid Acc: 0.54%\n",
      "\t scheduled_lr : 6.127444953468995e-06\n",
      "Epoch: 134 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.678 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 5.962488127733595e-06\n",
      "Epoch: 135 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.677 | Train Acc: 0.57%\n",
      "\t Valid Loss: 0.686 | Valid Acc: 0.54%\n",
      "\t scheduled_lr : 5.799056641831313e-06\n",
      "Epoch: 136 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.680 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.685 | Valid Acc: 0.54%\n",
      "\t scheduled_lr : 5.63719082003582e-06\n",
      "Epoch: 137 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.677 | Train Acc: 0.57%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 5.476930600316585e-06\n",
      "Epoch: 138 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.681 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.683 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 5.318315524484795e-06\n",
      "Epoch: 139 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.676 | Train Acc: 0.58%\n",
      "\t Valid Loss: 0.690 | Valid Acc: 0.54%\n",
      "\t scheduled_lr : 5.161384728437009e-06\n",
      "Epoch: 140 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.674 | Train Acc: 0.58%\n",
      "\t Valid Loss: 0.685 | Valid Acc: 0.54%\n",
      "\t scheduled_lr : 5.0061769324989475e-06\n",
      "Epoch: 141 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.678 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.686 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 4.85273043187183e-06\n",
      "Epoch: 142 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.675 | Train Acc: 0.57%\n",
      "\t Valid Loss: 0.685 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 4.701083087183629e-06\n",
      "Epoch: 143 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.677 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 4.551272315147488e-06\n",
      "Epoch: 144 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.679 | Train Acc: 0.57%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 4.403335079329736e-06\n",
      "Epoch: 145 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.677 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.685 | Valid Acc: 0.54%\n",
      "\t scheduled_lr : 4.257307881029689e-06\n",
      "Epoch: 146 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.680 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.686 | Valid Acc: 0.54%\n",
      "\t scheduled_lr : 4.1132267502734685e-06\n",
      "Epoch: 147 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.676 | Train Acc: 0.57%\n",
      "\t Valid Loss: 0.686 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 3.971127236924157e-06\n",
      "Epoch: 148 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.674 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.54%\n",
      "\t scheduled_lr : 3.831044401910396e-06\n",
      "Epoch: 149 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.676 | Train Acc: 0.57%\n",
      "\t Valid Loss: 0.687 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 3.6930128085756257e-06\n",
      "Epoch: 150 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.679 | Train Acc: 0.57%\n",
      "\t Valid Loss: 0.686 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 3.557066514150084e-06\n",
      "Epoch: 151 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.675 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.685 | Valid Acc: 0.54%\n",
      "\t scheduled_lr : 3.4232390613477115e-06\n",
      "Epoch: 152 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.678 | Train Acc: 0.57%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 3.291563470089986e-06\n",
      "Epoch: 153 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.678 | Train Acc: 0.57%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 3.1620722293587457e-06\n",
      "Epoch: 154 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.674 | Train Acc: 0.58%\n",
      "\t Valid Loss: 0.683 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 3.0347972891800186e-06\n",
      "Epoch: 155 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.674 | Train Acc: 0.57%\n",
      "\t Valid Loss: 0.685 | Valid Acc: 0.54%\n",
      "\t scheduled_lr : 2.9097700527408394e-06\n",
      "Epoch: 156 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.678 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 2.7870213686409813e-06\n",
      "Epoch: 157 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.674 | Train Acc: 0.57%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 2.6665815232815127e-06\n",
      "Epoch: 158 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.679 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.686 | Valid Acc: 0.54%\n",
      "\t scheduled_lr : 2.5484802333921013e-06\n",
      "Epoch: 159 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.676 | Train Acc: 0.57%\n",
      "\t Valid Loss: 0.685 | Valid Acc: 0.54%\n",
      "\t scheduled_lr : 2.4327466386988352e-06\n",
      "Epoch: 160 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.673 | Train Acc: 0.57%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 2.31940929473445e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 161 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.677 | Train Acc: 0.57%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.54%\n",
      "\t scheduled_lr : 2.208496165792663e-06\n",
      "Epoch: 162 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.678 | Train Acc: 0.57%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 2.100034618028411e-06\n",
      "Epoch: 163 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.678 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.54%\n",
      "\t scheduled_lr : 1.994051412705657e-06\n",
      "Epoch: 164 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.676 | Train Acc: 0.56%\n",
      "\t Valid Loss: 0.685 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 1.8905726995944627e-06\n",
      "Epoch: 165 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.675 | Train Acc: 0.58%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 1.7896240105188981e-06\n",
      "Epoch: 166 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.676 | Train Acc: 0.57%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 1.6912302530574644e-06\n",
      "Epoch: 167 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.676 | Train Acc: 0.57%\n",
      "\t Valid Loss: 0.685 | Valid Acc: 0.54%\n",
      "\t scheduled_lr : 1.5954157043975185e-06\n",
      "Epoch: 168 | Epoch Time: 0m 17s\n",
      "\t Train Loss: 0.676 | Train Acc: 0.58%\n",
      "\t Valid Loss: 0.684 | Valid Acc: 0.55%\n",
      "\t scheduled_lr : 1.502204005345236e-06\n"
     ]
    }
   ],
   "source": [
    "# GridSearch loop\n",
    "#ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
    "sampler = TPESampler(seed=42)\n",
    "study = optuna.create_study(\n",
    "    study_name=\"Retina_opt\",\n",
    "    direction=\"minimize\",\n",
    "    sampler=sampler,\n",
    ")\n",
    "study.optimize(GridSearch_loop, n_trials=10)\n",
    "print(\"Best Score:\", study.best_value)\n",
    "print(\"Best trial:\", study.best_trial.params)\n",
    "#ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "BangEnv",
   "language": "python",
   "name": "bangenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
